{"cells":[{"cell_type":"markdown","source":["**여기서부터는**\n","\n","실제 동영상에서 뽑아온 R값, HSSC값을 통해 학습하는 것을 해본다.\n","\n","\n"],"metadata":{"id":"EnGz8MNsOcjz"}},{"cell_type":"markdown","source":["우선 데이터를 불러와 30개씩 짤라서 출력해보자..\n","\n","X_train 만드는 과정이다. 여기서 작업해야 할 부분은,\n","1. R값, HSSC값을 colab에 마운트한다.\n","2. 맨 위의 파일 이름만 수정하면 된다."],"metadata":{"id":"MqBegOv-jAS7"}},{"cell_type":"code","source":["# 각각 Ra값, HSSC값 텍스트 파일은 열어서 읽어온다.\n","with open(\"Rvalue (21).txt\", \"r\") as f:\n","  rvalue = f.read();\n","\n","with open(\"HSSCvalue (21).txt\", \"r\") as f:\n","  hsscvalue = f.read();\n","\n","# 이때, 값들은 모두 문자열이고 ','로 구분이 되어 있기 때문에 split을 진행.\n","rList = rvalue.split(',')\n","hsscList = hsscvalue.split(',')\n","newRList = []\n","newHsscList = []\n","print(len(rList))\n","print(len(hsscList))\n","\n","for rl in rList:\n","  if rl[0] == '[':\n","    rl = rl[1:]\n","  if rl[len(rl)-1] == ']':\n","    rl = rl[:len(rl)-2]\n","  real = round(float(rl),3)\n","  newRList.append(real)\n","\n","for hl in hsscList:\n","  if hl[0] == '[':\n","    hl = hl[1:]\n","  if hl[len(hl)-1] == ']':\n","    hl = hl[:len(hl)-2]\n","  if hl == '':\n","    hl = 0\n","  real = round(float(hl),3)\n","  newHsscList.append(real)\n","\n","print(newRList)\n","print(newHsscList)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5P5scX5qrZx","executionInfo":{"status":"ok","timestamp":1684248392249,"user_tz":-540,"elapsed":3,"user":{"displayName":"홍민기","userId":"15890315418347205178"}},"outputId":"d5b2a3cb-9f5e-466e-d340-d50269ad0d0c"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["96\n","95\n","[0.249, 0.304, 0.31, 0.297, 0.297, 0.314, 0.277, 0.343, 0.295, 0.295, 0.367, 0.371, 0.341, 0.326, 0.336, 0.341, 0.385, 0.385, 0.366, 0.366, 0.371, 0.381, 0.372, 0.392, 0.416, 0.415, 0.422, 0.428, 0.43, 0.431, 0.429, 0.427, 0.439, 0.438, 0.442, 0.44, 0.442, 0.456, 0.454, 0.452, 0.454, 0.456, 0.456, 0.45, 0.457, 0.465, 0.441, 0.443, 0.433, 0.427, 0.427, 0.426, 0.42, 0.409, 0.418, 0.41, 0.391, 0.381, 0.371, 0.371, 0.383, 0.381, 0.377, 0.376, 0.376, 0.373, 0.37, 0.367, 0.348, 0.348, 0.357, 0.339, 0.33, 0.334, 0.334, 0.357, 0.357, 0.357, 0.354, 0.354, 0.338, 0.319, 0.32, 0.313, 0.315, 0.314, 0.315, 0.315, 0.315, 0.315, 0.315, 0.315, 0.315, 0.315, 0.315, 0.315]\n","[-0.229, -0.041, -0.257, 0.0, -0.088, -0.43, -0.161, -0.16, 0.0, -0.269, -0.171, -0.194, -0.156, -0.139, -0.119, -0.217, 0.0, -0.308, 0.0, -0.094, -0.083, -0.09, -0.151, -0.183, -0.136, -0.053, -0.102, -0.065, -0.056, -0.044, 0.054, -0.05, -0.022, -0.062, 0.07, -0.041, -0.066, -0.049, 0.027, 0.003, -0.05, 0.0, 0.172, -0.033, 0.094, 0.063, 0.095, 0.067, 0.164, 0.0, 0.107, 0.09, 0.193, 0.048, 0.301, 0.227, 0.151, 0.17, 0.0, 0.147, 0.209, 0.121, 0.209, 0.0, 0.098, 0.091, 0.285, 0.098, 0.0, 0.106, 0.097, 0.098, 0.095, 0.105, 0.097, 0.204, 0.0, -0.093, 0.0, 0.185, 0.138, 0.025, 0.086, 0.052, 0.018, 0.079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}]},{"cell_type":"markdown","source":["이제 y_train을 만드는 과정\n","\n","맨 위 코드는 사용하지 말고, 그 다음 셀 사용. 선택지 3가지 있음.\n","\n","맨 위는 낙상 + 정상이 합쳐졌을 때 사용하는 것으로 낙상이 계속 되다가 정상으로 되거나 그 반대의 경우 한쪽은 np.ones(a frame), 다른 한쪽은 np.zeros(b frame)으로 한 뒤 연결시켜줌.\n","\n","두 번째는 그냥 낙상만 쭉 or 정상만 쭉.\n","\n","세 번쨰는 뒤죽박죽 섞여 있어서 직접 입력"],"metadata":{"id":"fu9dZx97ufno"}},{"cell_type":"code","source":["import numpy as np\n","\n","\n","# y_train data 입력(각 np.zeros(), np.ones()에 프레임 수 만큼 입력.모든 수의 합은 len(HsscList))\n","pre_fall = np.zeros(95)\n","fall = np.ones(0)\n","post_fall = np.zeros(0)\n","new_data = np.concatenate([pre_fall, fall, post_fall], axis=0)\n","for i in range(len(newHsscList)-30):\n","  y = new_data[i:i+30]\n","  y_train = np.load('y_train.npy')\n","  y_train = np.concatenate([y_train, y.reshape(1, -1)], axis=0)\n","  np.save('y_train.npy', y_train)\n"],"metadata":{"id":"k_g2WCWRugwh","executionInfo":{"status":"ok","timestamp":1684248398391,"user_tz":-540,"elapsed":4,"user":{"displayName":"홍민기","userId":"15890315418347205178"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","for i in range(len(newHsscList)-30):\n","  x1 = np.array(newRList[i:i+30])\n","  x2 = np.array(newHsscList[i:i+30])\n","  re_x1 = np.expand_dims(x1, axis=1)\n","  re_x2 = np.expand_dims(x2, axis=1)\n","  merged = np.concatenate((re_x1, re_x2), axis=1)\n","  x = np.expand_dims(merged, axis=0)\n","  X_train = np.load('X_train.npy')\n","  X_train = np.concatenate((X_train, x), axis = 0)\n","  np.save('X_train.npy', X_train)"],"metadata":{"id":"ppTs7bJ_tQ7_","executionInfo":{"status":"ok","timestamp":1684248401695,"user_tz":-540,"elapsed":3,"user":{"displayName":"홍민기","userId":"15890315418347205178"}}},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":["진행상황 shape 확인.\n","\n","매번 X_train, y_train을 만들 때마다 아래 셀 실행시켜 확인."],"metadata":{"id":"uVlP1l_MvatJ"}},{"cell_type":"code","source":["X_train = np.load('X_train.npy')\n","y_train = np.load('y_train.npy')\n","print(X_train.shape)\n","print(y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CuLpy9Lavcst","executionInfo":{"status":"ok","timestamp":1684248859915,"user_tz":-540,"elapsed":3,"user":{"displayName":"홍민기","userId":"15890315418347205178"}},"outputId":"bec6d471-0eed-46ec-b1fd-0089a5848992"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["(1928, 30, 2)\n","(1928, 30)\n"]}]},{"cell_type":"markdown","source":["이제 밑은 학습시키는 과정."],"metadata":{"id":"Df60M0IFkb2H"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, GRU, Dense, Dropout\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","\n","# 시계열 데이터 생성\n","time_steps = 30\n","\n","X_train = np.load('X_train.npy')\n","\n","y_train = np.load('y_train.npy')\n","\n","history = []\n","\n","model = Sequential()\n","\n","model.add(GRU(32, return_sequences=True, input_shape=(30, 2)))\n","model.add(Dropout(0.2))\n","model.add(GRU(64, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n","\n","\n","\n","model.fit(X_train, y_train, epochs=100, batch_size = 32)\n","print(X_train.shape, y_train.shape)\n","model.summary()\n","\n","# test_loss, test_acc = model.evaluate(X_test, y_test)\n","# print('Test accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bc2fbqi-rnvr","executionInfo":{"status":"ok","timestamp":1684248938286,"user_tz":-540,"elapsed":65343,"user":{"displayName":"홍민기","userId":"15890315418347205178"}},"outputId":"c56ff572-dcd5-4276-e3ef-39ceb29fe6c8"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","61/61 [==============================] - 5s 9ms/step - loss: 0.3654 - accuracy: 0.8891\n","Epoch 2/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.2013 - accuracy: 0.9219\n","Epoch 3/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1894 - accuracy: 0.9251\n","Epoch 4/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1790 - accuracy: 0.9285\n","Epoch 5/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1720 - accuracy: 0.9307\n","Epoch 6/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.1657 - accuracy: 0.9327\n","Epoch 7/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.1614 - accuracy: 0.9349\n","Epoch 8/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.1537 - accuracy: 0.9366\n","Epoch 9/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.1448 - accuracy: 0.9389\n","Epoch 10/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1357 - accuracy: 0.9436\n","Epoch 11/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1284 - accuracy: 0.9473\n","Epoch 12/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1241 - accuracy: 0.9490\n","Epoch 13/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1170 - accuracy: 0.9529\n","Epoch 14/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1122 - accuracy: 0.9546\n","Epoch 15/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.9559\n","Epoch 16/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.9559\n","Epoch 17/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.1003 - accuracy: 0.9592\n","Epoch 18/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0980 - accuracy: 0.9595\n","Epoch 19/100\n","61/61 [==============================] - 1s 10ms/step - loss: 0.1002 - accuracy: 0.9586\n","Epoch 20/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0964 - accuracy: 0.9613\n","Epoch 21/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0933 - accuracy: 0.9614\n","Epoch 22/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0906 - accuracy: 0.9627\n","Epoch 23/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0899 - accuracy: 0.9630\n","Epoch 24/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0896 - accuracy: 0.9624\n","Epoch 25/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0869 - accuracy: 0.9638\n","Epoch 26/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0837 - accuracy: 0.9646\n","Epoch 27/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.0835 - accuracy: 0.9647\n","Epoch 28/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0832 - accuracy: 0.9645\n","Epoch 29/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.0812 - accuracy: 0.9655\n","Epoch 30/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0811 - accuracy: 0.9651\n","Epoch 31/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0767 - accuracy: 0.9669\n","Epoch 32/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0791 - accuracy: 0.9656\n","Epoch 33/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0736 - accuracy: 0.9683\n","Epoch 34/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0737 - accuracy: 0.9683\n","Epoch 35/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0711 - accuracy: 0.9700\n","Epoch 36/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0714 - accuracy: 0.9699\n","Epoch 37/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0715 - accuracy: 0.9692\n","Epoch 38/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0703 - accuracy: 0.9697\n","Epoch 39/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0739 - accuracy: 0.9684\n","Epoch 40/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0686 - accuracy: 0.9710\n","Epoch 41/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0681 - accuracy: 0.9698\n","Epoch 42/100\n","61/61 [==============================] - 1s 11ms/step - loss: 0.0651 - accuracy: 0.9720\n","Epoch 43/100\n","61/61 [==============================] - 1s 11ms/step - loss: 0.0637 - accuracy: 0.9719\n","Epoch 44/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0642 - accuracy: 0.9721\n","Epoch 45/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0658 - accuracy: 0.9718\n","Epoch 46/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0621 - accuracy: 0.9721\n","Epoch 47/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0619 - accuracy: 0.9733\n","Epoch 48/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.0618 - accuracy: 0.9733\n","Epoch 49/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0645 - accuracy: 0.9718\n","Epoch 50/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0597 - accuracy: 0.9741\n","Epoch 51/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0589 - accuracy: 0.9740\n","Epoch 52/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0605 - accuracy: 0.9732\n","Epoch 53/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0576 - accuracy: 0.9746\n","Epoch 54/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0585 - accuracy: 0.9735\n","Epoch 55/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0583 - accuracy: 0.9735\n","Epoch 56/100\n","61/61 [==============================] - 1s 10ms/step - loss: 0.0565 - accuracy: 0.9747\n","Epoch 57/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0577 - accuracy: 0.9747\n","Epoch 58/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0569 - accuracy: 0.9754\n","Epoch 59/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0552 - accuracy: 0.9752\n","Epoch 60/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0559 - accuracy: 0.9746\n","Epoch 61/100\n","61/61 [==============================] - 1s 10ms/step - loss: 0.0552 - accuracy: 0.9749\n","Epoch 62/100\n","61/61 [==============================] - 1s 10ms/step - loss: 0.0552 - accuracy: 0.9761\n","Epoch 63/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0560 - accuracy: 0.9754\n","Epoch 64/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0544 - accuracy: 0.9757\n","Epoch 65/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0540 - accuracy: 0.9764\n","Epoch 66/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0536 - accuracy: 0.9762\n","Epoch 67/100\n","61/61 [==============================] - 1s 10ms/step - loss: 0.0529 - accuracy: 0.9762\n","Epoch 68/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0526 - accuracy: 0.9767\n","Epoch 69/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.0513 - accuracy: 0.9770\n","Epoch 70/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.0519 - accuracy: 0.9772\n","Epoch 71/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.0527 - accuracy: 0.9762\n","Epoch 72/100\n","61/61 [==============================] - 1s 12ms/step - loss: 0.0507 - accuracy: 0.9771\n","Epoch 73/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9768\n","Epoch 74/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0533 - accuracy: 0.9757\n","Epoch 75/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9777\n","Epoch 76/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0558 - accuracy: 0.9751\n","Epoch 77/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0515 - accuracy: 0.9769\n","Epoch 78/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9771\n","Epoch 79/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0505 - accuracy: 0.9767\n","Epoch 80/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0485 - accuracy: 0.9784\n","Epoch 81/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0500 - accuracy: 0.9776\n","Epoch 82/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0491 - accuracy: 0.9775\n","Epoch 83/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0480 - accuracy: 0.9785\n","Epoch 84/100\n","61/61 [==============================] - 1s 10ms/step - loss: 0.0480 - accuracy: 0.9783\n","Epoch 85/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0480 - accuracy: 0.9783\n","Epoch 86/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0476 - accuracy: 0.9788\n","Epoch 87/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0485 - accuracy: 0.9779\n","Epoch 88/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0470 - accuracy: 0.9786\n","Epoch 89/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0468 - accuracy: 0.9788\n","Epoch 90/100\n","61/61 [==============================] - 1s 10ms/step - loss: 0.0463 - accuracy: 0.9788\n","Epoch 91/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0467 - accuracy: 0.9786\n","Epoch 92/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0475 - accuracy: 0.9783\n","Epoch 93/100\n","61/61 [==============================] - 1s 13ms/step - loss: 0.0471 - accuracy: 0.9787\n","Epoch 94/100\n","61/61 [==============================] - 1s 11ms/step - loss: 0.0468 - accuracy: 0.9786\n","Epoch 95/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0469 - accuracy: 0.9782\n","Epoch 96/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0458 - accuracy: 0.9792\n","Epoch 97/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0474 - accuracy: 0.9785\n","Epoch 98/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0455 - accuracy: 0.9792\n","Epoch 99/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0466 - accuracy: 0.9784\n","Epoch 100/100\n","61/61 [==============================] - 1s 9ms/step - loss: 0.0455 - accuracy: 0.9790\n","(1928, 30, 2) (1928, 30)\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," gru_4 (GRU)                 (None, 30, 32)            3456      \n","                                                                 \n"," dropout_4 (Dropout)         (None, 30, 32)            0         \n","                                                                 \n"," gru_5 (GRU)                 (None, 30, 64)            18816     \n","                                                                 \n"," dropout_5 (Dropout)         (None, 30, 64)            0         \n","                                                                 \n"," dense_2 (Dense)             (None, 30, 1)             65        \n","                                                                 \n","=================================================================\n","Total params: 22,337\n","Trainable params: 22,337\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["'''\n","사용한 데이터셋 종류\n","test5.mp4 -> 3개\n","test6.mp4 -> 2개\n","test8.mp4 -> 4개\n","test9.mov -> 2개\n","test10.mov -> 3개\n","test11.mov -> (낙상 43frame, 해제 89frame)\n","\n","URFD-FALL\n","FALL1~5까지 완료. -> 여기까지 total 588개\n","FALL ~10까지 완료 -> 여기까지 total 1100개\n","\n","추가 기록 내용 : \n","FALL-13,14,16,18~(가방)은 MULTIPLEPOSES로 해야함. -> \n","-> 결국 MULTIPLEPOSES로 해야하는거 제외하면 여기까지 total 1386개.\n","\n","\n","'''"],"metadata":{"id":"knZ8xTk96yc0"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1JzGUX-udQDlRqTd4-X4BSp0TL9DDd7le","timestamp":1684213855518}],"gpuType":"T4","authorship_tag":"ABX9TyMambEptrJvxWs/5Yp1XPWp"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}